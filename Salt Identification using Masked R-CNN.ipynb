{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is training the model for the [salt identification challange](https://www.kaggle.com/c/tgs-salt-identification-challenge) on kaggle. The link to this notbook on Kaggle is https://www.kaggle.com/smehta12/find-salt-using-masked-r-cnn/\n",
    "\n",
    "It explains how to use Masked RCNN to identify the salt from given images and its masks. It uses the matterport's [implemetation](https://github.com/matterport/Mask_RCNN) which is well known MRCNN implementation in the Kaggle community. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input/train\"))\n",
    "\n",
    "root_dir = r\"C:\\my_projects\\tgs_salt\" #\"../input/train/images\"\n",
    "train_img_dir= \"train\\images\"\n",
    "train_masks_dir = \"train\\masks\"\n",
    "tests_dir = r\"C:\\my_projects\\tgs_salt\\test\\images\"#\"../input/test/images\"\n",
    "#masks_csv = \"..input/test/train.csv\"\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "ORIG_IMG_HEIGHT=101\n",
    "ORIG_IMG_WIDTH=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Install the matterport's masked R-CNN on Kaggle kernel\n",
    "import subprocess\n",
    "subprocess.call([\"pip\" ,\"install\", \"git+git://github.com/matterport/Mask_RCNN.git\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d4253ed71a8c96435bb50d03402f5e43a7a95812"
   },
   "outputs": [],
   "source": [
    "# import required package from Masked R-CNN\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3df58cb697cfd2a1579c8d7bb88f6e6f2b35e10f"
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's look at some data. We can see that TGS chose to use very varied data by inspecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\n",
    "plt.figure(figsize=(20,10))\n",
    "for j, img_name in enumerate(ids):\n",
    "    q = j+1\n",
    "    img = plt.imread(os.path.join(root_dir, train_img_dir, img_name + '.png'))\n",
    "    img_mask = plt.imread(os.path.join(root_dir, train_masks_dir, img_name + '.png'))\n",
    "    \n",
    "    plt.subplot(1,2*(1+len(ids)),q*2-1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1,2*(1+len(ids)),q*2)\n",
    "    plt.imshow(img_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV below contains the id of the train images and the rle masks. From this csv we'll only use ids and the masks will be loaded from the train mask dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "554e7198c39de01a6294d37d887a5397afff3c53"
   },
   "outputs": [],
   "source": [
    "# Load csv\n",
    "train_csv=os.path.join(root_dir, \"train.csv\")\n",
    "train_img_info = pd.read_csv(train_csv)\n",
    "train_img_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations for the training the masked RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "088dcab813dfbbd54a5476e576012fac1722d162"
   },
   "outputs": [],
   "source": [
    "# The following parameters have been selected to reduce running time for demonstration purposes \n",
    "# These may not be optimal.\n",
    "\n",
    "class SaltConfig(Config):\n",
    "     # Give the configuration a recognizable name  \n",
    "    NAME = 'find_salt'\n",
    "    \n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8 \n",
    "    \n",
    "    BACKBONE = 'resnet50'\n",
    "    \n",
    "    NUM_CLASSES = 2  # no mask + 1 pneumonia classes\n",
    "    \n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
    "    TRAIN_ROIS_PER_IMAGE = 16\n",
    "    MAX_GT_INSTANCES = 1\n",
    "    DETECTION_MAX_INSTANCES = 3\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    DETECTION_NMS_THRESHOLD = 0.1\n",
    "    TOP_DOWN_PYRAMID_SIZE = 128\n",
    "\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    \n",
    "config = SaltConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify whether the image has salt present or not based on the RLE masks. \n",
    "# If RLE mask present in the train df then it has salt else it doesn't has it.\n",
    "\n",
    "train_img_info[\"has_salt\"] = ~train_img_info[\"rle_mask\"].isnull()\n",
    "train_img_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide the information of the dataset to the algorithm\n",
    "\n",
    "The class below retains the information of the data set including the images and the masks. It also acts as the utility to read back the image info and masks info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "536fda5f209edebb594cf4ab0d9e9c254bf11c2a"
   },
   "outputs": [],
   "source": [
    "class SaltDataSet(utils.Dataset):\n",
    "    \n",
    "    def __init__(self, image_files, root_dir, raw_img_dir, mask_img_dir, has_mask, orig_height, orig_width):\n",
    "        super(SaltDataSet, self).__init__(self)\n",
    "        \n",
    "        self.add_class('salt_shape',1, 'salt')\n",
    "        \n",
    "        for i, image_id in enumerate(image_files):\n",
    "            fp = os.path.join(root_dir, raw_img_dir, image_id+\".png\")\n",
    "            mask_fp=os.path.join(root_dir, mask_img_dir, image_id+\".png\")\n",
    "            self.add_image('salt_shape', image_id=i, path=fp,\n",
    "                           orig_height=orig_height, orig_width=orig_width, mask_fp=mask_fp, has_mask=has_mask[i])\n",
    "    \n",
    "    def get_img_info(self, img_id):\n",
    "        return self.image_info[img_id]\n",
    "    \n",
    "    def get_random_img_id(self):\n",
    "        return random.choice(list(range(len(self.image_info))))\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        has_mask=info[\"has_mask\"]\n",
    "        fp = info['mask_fp']\n",
    "        \n",
    "        mask_img = plt.imread(fp)\n",
    "        mask=np.reshape(mask_img, mask_img.shape + (1,))\n",
    "        \n",
    "        if not has_mask:\n",
    "            class_ids=np.zeros((1,), dtype=np.int32)\n",
    "        else:\n",
    "            class_ids=np.ones((1,), dtype=np.int32)\n",
    "        \n",
    "        return mask, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids=train_img_info[\"id\"].tolist()\n",
    "######################################################################\n",
    "# Modify this line to use more or fewer images for training/validation. \n",
    "# To use all images, do: image_fps_list = list(image_fps)\n",
    "image_id_list = list(image_ids[:1000]) \n",
    "#####################################################################\n",
    "\n",
    "# split dataset into training vs. validation dataset \n",
    "# split ratio is set to 0.9 vs. 0.1 (train vs. validation, respectively)\n",
    "validation_split = 0.1\n",
    "\n",
    "sorted(image_id_list)\n",
    "random.seed(42)\n",
    "random.shuffle(image_id_list)\n",
    "split_index = int((1 - validation_split) * len(image_id_list))\n",
    "\n",
    "image_id_train = image_id_list[:split_index]\n",
    "image_id_val = image_id_list[split_index:]\n",
    "\n",
    "print(len(image_id_train), len(image_id_val))\n",
    "print(image_id_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_id_train = train_img_info[train_img_info[\"id\"].isin(image_id_train)]\n",
    "df_image_id_train.reset_index(drop=True)\n",
    "print(df_image_id_train.shape)\n",
    "\n",
    "\n",
    "df_image_id_val = train_img_info[train_img_info[\"id\"].isin(image_id_val)]\n",
    "df_image_id_val.reset_index(drop=True)\n",
    "print(df_image_id_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide info about train and validation images to the SaltDataSet class\n",
    "\n",
    "dataset_train = SaltDataSet(df_image_id_train[\"id\"].tolist(), root_dir, train_img_dir, train_masks_dir,\n",
    "                            df_image_id_train[\"has_salt\"].tolist(), ORIG_IMG_HEIGHT, ORIG_IMG_WIDTH)\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = SaltDataSet(df_image_id_val[\"id\"].tolist(), root_dir, train_img_dir, train_masks_dir,\n",
    "                            df_image_id_val[\"has_salt\"].tolist(), ORIG_IMG_HEIGHT, ORIG_IMG_WIDTH)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show info about random image\n",
    "\n",
    "image_id = dataset_train.get_random_img_id()\n",
    "dataset_train.get_img_info(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display random samples and their bounding boxes\n",
    "# Suggestion: Run this a few times to see different examples. \n",
    "\n",
    "image_id = dataset_train.get_random_img_id()\n",
    "image_fp = dataset_train.image_reference(image_id)\n",
    "image = dataset_train.load_image(image_id)\n",
    "mask, class_ids = dataset_train.load_mask(image_id)\n",
    "\n",
    "print(dataset_train.get_img_info(image_id))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image[:, :, 0], cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "masked = np.zeros(image.shape[:2])\n",
    "for i in range(mask.shape[2]):\n",
    "    masked += image[:, :, 0] * mask[:, :, i]\n",
    "plt.imshow(masked, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "\n",
    "\n",
    "Note: the following model is for demonstration purpose only. The epochs is limited to 5 but it can be modified or extend to generate the models based on multiple epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir= os.path.join(root_dir,\"model\")\n",
    "print(model_dir)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = [5]#, 10]\n",
    "\n",
    "import warnings \n",
    "import time\n",
    "\n",
    "\n",
    "for epoch in NUM_EPOCHS:\n",
    "    \n",
    "    model_dir= os.path.join(root_dir, \"model_{}\".format(epoch))\n",
    "    print(model_dir)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model = modellib.MaskRCNN(mode='training', config=config, model_dir=model_dir)\n",
    "\n",
    "    # Train Mask-RCNN Model \n",
    "    start_time = time.time()\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    model.train(dataset_train, dataset_val, \n",
    "                learning_rate=config.LEARNING_RATE, \n",
    "                epochs=epoch, \n",
    "                layers='all'\n",
    "               )\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"completion time:{}\".format((start_time-end_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR=os.path.join(root_dir, \"model_5\")\n",
    "\n",
    "class InferenceConfig(SaltConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "model_path = model.find_last()\n",
    "print(model_path)\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset_val.image_ids)\n",
    "print(dataset_val.get_img_info(image_id))\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def rle_encode(binary_mask):\n",
    "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
    "    counts = rle.get('counts')\n",
    "    for i, (value, elements) in enumerate(groupby(binary_mask.ravel(order='F'))):\n",
    "        if i == 0 and value == 1:\n",
    "            counts.append(0)\n",
    "        counts.append(len(list(elements)))\n",
    "    print(rle['counts'])\n",
    "    return rle\n",
    "\n",
    "print(rle_encode(r[\"masks\"]))\n",
    "\n",
    "plt.imshow(r[\"masks\"].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=os.listdir(tests_dir)\n",
    "test_images = list(map(lambda x:os.path.join(tests_dir, x), test_images))\n",
    "test_images[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the multiple image and Prepare for submission\n",
    "\n",
    "Here, the salt identification is derieved based on the model generated above and it converts the binary mask to RLE. It will generate the dataframe for each provided test image id and the RLE mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_paths, min_conf=0.95):\n",
    "    \n",
    "    submission_dict=[]\n",
    "       \n",
    "    # assume square image\n",
    "    resize_factor = ORIG_IMG_HEIGHT / config.IMAGE_SHAPE[0]\n",
    "    \n",
    "    prev_mask=None\n",
    "    #resize_factor = ORIG_SIZE \n",
    "    for image_id in tqdm(image_paths): \n",
    "        image = plt.imread(image_id)\n",
    "        \n",
    "        print(image_id)\n",
    "        \n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1) \n",
    "        image, window, scale, padding, crop = utils.resize_image(\n",
    "            image,\n",
    "            min_dim=config.IMAGE_MIN_DIM,\n",
    "            min_scale=config.IMAGE_MIN_SCALE,\n",
    "            max_dim=config.IMAGE_MAX_DIM,\n",
    "            mode=config.IMAGE_RESIZE_MODE)\n",
    "            \n",
    "        print(image.shape)\n",
    "        salt_img_id = os.path.basename(image_id).split(\".\")[0]\n",
    "        \n",
    "        results = model.detect([image])\n",
    "        r = results[0]\n",
    "        \n",
    "        print(r[\"masks\"].shape)\n",
    "        \n",
    "        if prev_mask:\n",
    "            print(\"array equal:{}\".format(np.array_equal(r[\"masks\"], prev_mask)))\n",
    "        prev_mask = r[\"masks\"]\n",
    "        \n",
    "        plt.imshow(np.squeeze(r[\"masks\"]))\n",
    "        \n",
    "        assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )\n",
    "        \n",
    "        rle_mask=rle_encode(r['masks'])[\"counts\"]\n",
    "        \n",
    "        rle_mask=\" \".join(map(str, rle_mask))\n",
    "                \n",
    "        submission_dict.append({\"id\":salt_img_id, \"rle_mask\":rle_mask})\n",
    "\n",
    "                               \n",
    "    submission_df=pd.DataFrame(submission_dict)\n",
    "    \n",
    "    print(submission_df.head())\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = predict(test_images[:5])\n",
    "submission_df.to_csv(os.path.join(root_dir, \"submission.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
